ğŸš€ Kayak â€“ Distributed Systems Project (Kafka Middleware + AI Ingestion)
Final Project â€“ Tier-2 Middleware: Kafka-Based Event Pipeline

This README explains how to run the Kafka pipeline, how ingestion works, how booking/billing events flow, and how to run the CSVâ†’Kafka AI ingestion using Python.

This document is meant for all team members so everyone can run the system without needing manual guidance.




ğŸ“¦ 1. Prerequisites

Install the following:

Docker Desktop

Node.js 18+

Python 3.10+

pip

VSCode (recommended)




ğŸ³ 2. Start Kafka Using Docker

Navigate to:

Kayak/src/infra

Start Kafka + Zookeeper:

docker-compose up -d


Verify containers:

docker ps


Expected containers:

kayak-kafka

kayak-zookeeper


ğŸ§µ 3. Create Required Kafka Topics

docker exec kayak-kafka \
  kafka-topics --bootstrap-server localhost:9092 \
  --create --if-not-exists --topic booking_created --partitions 3 --replication-factor 1

docker exec kayak-kafka \
  kafka-topics --bootstrap-server localhost:9092 \
  --create --if-not-exists --topic booking_updated --partitions 3 --replication-factor 1

docker exec kayak-kafka \
  kafka-topics --bootstrap-server localhost:9092 \
  --create --if-not-exists --topic payment_succeeded --partitions 3 --replication-factor 1

docker exec kayak-kafka \
  kafka-topics --bootstrap-server localhost:9092 \
  --create --if-not-exists --topic payment_failed --partitions 3 --replication-factor 1

docker exec kayak-kafka \
  kafka-topics --bootstrap-server localhost:9092 \
  --create --if-not-exists --topic user_tracking --partitions 3 --replication-factor 1

docker exec kayak-kafka \
  kafka-topics --bootstrap-server localhost:9092 \
  --create --if-not-exists --topic click_event --partitions 3 --replication-factor 1

docker exec kayak-kafka \
  kafka-topics --bootstrap-server localhost:9092 \
  --create --if-not-exists --topic raw_supplier_feeds --partitions 3 --replication-factor 1




ğŸ“¡ 4. How to Consume Kafka Messages

Example: listen to booking_created:

docker exec -it kayak-kafka \
  kafka-console-consumer --bootstrap-server localhost:9092 \
  --topic booking_created --from-beginning


Example: listen to raw_supplier_feeds:

docker exec -it kayak-kafka \
  kafka-console-consumer --bootstrap-server localhost:9092 \
  --topic raw_supplier_feeds --from-beginning



  ğŸ§© 5. Node.js Kafka Integration
Shared Kafka client is located at:
src/services/common/src/kafka/kafkaClient.ts

Sends messages using:
await sendKafkaMessage(KAFKA_TOPICS.PAYMENT_SUCCEEDED, payload)





ğŸ’³ 6. Billing Service â†’ Kafka (Payment Events)

Billing controller automatically publishes:

payment_succeeded

payment_failed

To test billing producer:

npx ts-node src/services/common/src/kafka/manualPaymentTest.ts


Expected output:

Kafka producer connected
Sent message to topic payment_succeeded
Done.





ğŸ“Š 7. Analytics Service Kafka Consumer

Navigate:

src/services/analytics-service


Install deps:

npm install


Run analytics Kafka consumer:

npx ts-node src/kafka/bookingPaymentConsumer.ts


You should see:

Analytics consumer listening on booking/payment topics...
[Analytics] topic=booking_created ...
[Analytics] topic=payment_succeeded ...




ğŸ¤– 8. AI Recommendation Service â€“ CSV â†’ Kafka Producer

Navigate to AI directory:

cd Kayak/ai-recommendation


Install Python dependencies:

pip install -r requirements.txt

Place your Kaggle dataset CSVs here:
ai-recommendation/data/raw/


Example:

ai-recommendation/data/raw/hotel_prices_sample.csv

Running the CSV â†’ Kafka producer

Set Kafka servers:

set KAFKA_BOOTSTRAP_SERVERS=localhost:9092


Run the producer:

python -m app.deals_agent.csv_producer


Expected output:

[CSV->Kafka] Sent 100 messages to topic 'raw_supplier_feeds'

Confirm in Kafka:
docker exec -it kayak-kafka \
  kafka-console-consumer --bootstrap-server localhost:9092 \
  --topic raw_supplier_feeds --from-beginning


You will see flight/hotel rows streaming in JSON.





ğŸ§  9. AI Kafka Consumer (Optional â€“ Team Member Work)

Your teammate will implement:

deals.normalized

deals.scored

deals.tagged

scoring rules

websocket notifications

You donâ€™t need to do this part unless asked.

ğŸ“ 10. Folder Structure (Important)
Kayak/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ infra/ (Kafka Docker compose)
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ booking-billing-service
â”‚   â”‚   â”œâ”€â”€ analytics-service
â”‚   â”‚   â””â”€â”€ common (Kafka shared client)
â”‚
â”œâ”€â”€ ai-recommendation/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ kafka/ (Python producer & consumer)
â”‚   â”‚   â”œâ”€â”€ deals_agent/
â”‚   â”‚   â”œâ”€â”€ schemas/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ raw/ (CSV files go here)



ğŸ§ª 11. Manual Test: Produce + Consume
Produce
npx ts-node src/services/common/src/kafka/manualPaymentTest.ts

Consume
docker exec -it kayak-kafka kafka-console-consumer --bootstrap-server localhost:9092 --topic payment_succeeded --from-beginning

ğŸŸ¦ 12. Troubleshooting
CSV not found?

Ensure data is here:

ai-recommendation/data/raw/hotel_prices_sample.csv

Kafka connection timeout?

Restart Kafka:

docker-compose down
docker-compose up -d